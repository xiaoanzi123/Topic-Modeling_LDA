{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lda:n_documents: 17796\n",
      "INFO:lda:vocab_size: 5000\n",
      "INFO:lda:n_words: 277945\n",
      "INFO:lda:n_topics: 17\n",
      "INFO:lda:n_iter: 100\n",
      "WARNING:lda:all zero row in document-term matrix found\n",
      "/Users/chenanfan/anaconda3/lib/python3.6/site-packages/lda/utils.py:55: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if sparse and not np.issubdtype(doc_word.dtype, int):\n",
      "INFO:lda:<0> log likelihood: -3533080\n",
      "INFO:lda:<10> log likelihood: -2452015\n",
      "INFO:lda:<20> log likelihood: -2344982\n",
      "INFO:lda:<30> log likelihood: -2307707\n",
      "INFO:lda:<40> log likelihood: -2289530\n",
      "INFO:lda:<50> log likelihood: -2278324\n",
      "INFO:lda:<60> log likelihood: -2270771\n",
      "INFO:lda:<70> log likelihood: -2264765\n",
      "INFO:lda:<80> log likelihood: -2259733\n",
      "INFO:lda:<90> log likelihood: -2255918\n",
      "INFO:lda:<99> log likelihood: -2252142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model done\n",
      "shape: (17, 5000)\n",
      "['01', '04', '08']\n",
      "[[5.80315692e-07 5.80315692e-07 5.80315692e-07]\n",
      " [3.33355557e-07 3.33355557e-07 3.33355557e-07]\n",
      " [4.95172072e-07 4.95172072e-07 4.95172072e-07]\n",
      " [5.44188071e-07 5.44188071e-07 5.44188071e-07]\n",
      " [7.29767204e-07 1.46683208e-04 7.29767204e-07]\n",
      " [1.19331742e-06 1.19331742e-06 1.19331742e-06]\n",
      " [5.33276451e-07 5.33276451e-07 5.33276451e-07]\n",
      " [6.15437158e-04 7.52049180e-04 9.56967213e-04]\n",
      " [8.90630566e-07 8.90630566e-07 8.90630566e-07]\n",
      " [5.22766480e-07 5.22766480e-07 5.22766480e-07]\n",
      " [8.01860316e-07 8.01860316e-07 8.01860316e-07]\n",
      " [4.43109987e-04 6.32111252e-07 6.32111252e-07]\n",
      " [9.33794005e-07 9.33794005e-07 9.33794005e-07]\n",
      " [2.94524784e-07 5.91994816e-05 2.94524784e-07]\n",
      " [1.22549020e-06 1.22549020e-06 1.22549020e-06]\n",
      " [5.76302444e-07 5.76302444e-07 5.82065468e-05]\n",
      " [1.14982178e-06 1.14982178e-06 1.14982178e-06]]\n",
      "topic: 0 sum: 0.9999999999999535\n",
      "topic: 1 sum: 1.0000000000000313\n",
      "topic: 2 sum: 1.0000000000001095\n",
      "topic: 3 sum: 0.9999999999999603\n",
      "topic: 4 sum: 0.999999999999928\n",
      "topic: 5 sum: 0.9999999999999885\n",
      "topic: 6 sum: 1.0000000000000693\n",
      "topic: 7 sum: 0.9999999999999385\n",
      "topic: 8 sum: 0.9999999999999527\n",
      "topic: 9 sum: 1.0000000000000078\n",
      "topic: 10 sum: 0.9999999999999715\n",
      "topic: 11 sum: 0.9999999999999512\n",
      "*Topic 0\n",
      "- 教育 孩子 希望 生活 父母 真相 道德 世界 国家 图书馆 地方 可怕 人类 短裙 选择 工作 值得 利用 复出 精神\n",
      "*Topic 1\n",
      "- 受害者 权力 女性 希望 法律 讨论 权利 关系 改变 国家 理解 舆论 平等 道德 教育 性别 发声 面对 曝光 正义\n",
      "*Topic 2\n",
      "- 发展 女孩 一方 女儿 恶心 可怕 世界 困扰 晚上 前提 父母 单相思 男人 危害 想起 妈妈 生活 害怕 升职 另一方\n",
      "*Topic 3\n",
      "- 法律 证据 调查 关注 猥亵 女性 包括 希望 骚扰 侵害 强奸 犯罪 保护 情况 案件 案例 公开 相关 自杀 大学生\n",
      "*Topic 4\n",
      "- 举报 实名 取消 教师资格 资格 女博士 通报 调查 撤销 职务 工作 国家 发布 计划 手机 涉事 公布 网上 关系 相关\n",
      "*Topic 5\n",
      "- 女性 暴露 穿着 职业 小姐姐 言论 小姐 反击 职位 各行各业 面对 爆炸 日常生活 占据 韩剧 断过 作揖 举足轻重 最易 解气\n",
      "*Topic 6\n",
      "- 保护 教育 孩子 家长 儿童 防性 希望 活动 自我 侵害 暴力 知识 防范 意识 儿童性 小学 身体 未成年人 女童 关注\n",
      "*Topic 7\n",
      "- 美国 指控 女性 时间 报告 遭受 舆论 生存 职业 教育 矛盾 腐败 好莱坞 受害者 沦为 体面 一次次 侵案 公司 炮灰\n",
      "*Topic 8\n",
      "- 遭遇 沉默 面对 勇敢 受害者 女性 职场 公交车 权利 地铁 选择 公交 肢体 保护 尴尬 无意 女孩 发声 令人厌恶 维权\n",
      "*Topic 9\n",
      "- 恶心 喜欢 微笑 允悲 女性 职场 骚扰 公司 同事 工作 粉丝 doge 看点 二哈 特别 吃饭 男人 女人 身边 朋友\n",
      "*Topic 10\n",
      "- 幼儿园 疫苗 男子 家长 侵案 大学生 女孩 电性 颜色 保安 演讲 报警 书院 三种 事后 豫章 提到 17 阴影 猥亵\n",
      "*Topic 11\n",
      "- 起诉 姑息 容忍 第一 遭性 高校教师 侵害 国学 国内 严肃处理 师德 举报 时间 涉事 相关 成立 首例 免职 猥亵 研究\n",
      "*Topic 12\n",
      "- 举报 山东 实名 中医药大学 梁栋 副教授 猥亵 宿舍 调查 希望 仇英燃 曝光 大学生 耳光 有过 回复 领导 发出 山东省 举报信\n",
      "*Topic 13\n",
      "- 女性 喜欢 朋友 希望 男人 骚扰 保护 女孩子 男性 恶心 伤害 女孩 是因为 关系 女人 世界 告诉 经历 特别 不想\n",
      "*Topic 14\n",
      "- 机制 工作 建立 全国 24 制度 杭州 报案 出台 未成年人 意见 未成年 包括 教育局 处置 私下 调解 检察机关 瞒报 禁止\n",
      "*Topic 15\n",
      "- 自杀 调查 举报 指性 致其 警方 处分 发布 工作 声明 年前 情况 文学院 此事 师德 关注 记者 实名 相关 涉嫌\n",
      "*Topic 16\n",
      "- 美国 孩子 留学生 教学 校医 防性 侵案 教育 南加州 分享 动画 分钟 伤害 师生恋 目标 侵害 机构 工作 儿童 远离\n"
     ]
    }
   ],
   "source": [
    "import lda\n",
    "import pandas as pd\n",
    "import jieba\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "\n",
    "def open_dict(Dict):\n",
    "    path = '%s.txt' % Dict\n",
    "    dictionary = open(path, 'r', encoding='utf-8')\n",
    "    dict = []\n",
    "    for word in dictionary:\n",
    "        word = word.strip('\\n')\n",
    "        dict.append(word)\n",
    "    return dict\n",
    "\n",
    "clearwords=open_dict('clearwords')\n",
    "\n",
    "#分词\n",
    "def chinese_word_cut(mytext):\n",
    "    tempcut=jieba.cut(str(mytext))\n",
    "    return \" \".join(set(tempcut)-set(clearwords))\n",
    "\n",
    "#打印前n_top_words关键词\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()\n",
    "\n",
    "df = pd.read_excel(\"metoo20181221.xlsx\",'Sheet1',index_col=None,na_values=['NA'])\n",
    "df.shape\n",
    "df[\"content_cutted\"] = df.content.apply(chinese_word_cut)\n",
    "n_features = 5000\n",
    "\n",
    "tf_vectorizer = CountVectorizer(strip_accents = 'unicode',\n",
    "                                max_features=n_features,\n",
    "                                stop_words='english',\n",
    "                                max_df = 0.5,\n",
    "                                min_df = 10)\n",
    "tf = tf_vectorizer.fit_transform(df.content_cutted)\n",
    "vocab=tf_vectorizer.get_feature_names()\n",
    "model = lda.LDA(n_topics=17, n_iter=100, random_state=1)  \n",
    "model.fit(tf)\n",
    "print('model done')\n",
    "\n",
    "#主题-单词（topic-word）分布\n",
    "topic_word = model.topic_word_ \n",
    "print(\"shape: {}\".format(topic_word.shape))\n",
    "print(vocab[:3])\n",
    "print(topic_word[:, :3])\n",
    "for n in range(12):\n",
    "    sum_pr = sum(topic_word[n,:])  \n",
    "    print(\"topic: {} sum: {}\".format(n, sum_pr))\n",
    "\n",
    "#计算各主题Top-N个单词\n",
    "import numpy as np\n",
    "n = 20\n",
    "for i, topic_dist in enumerate(topic_word):  \n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n+1):-1]  \n",
    "    print('*Topic {}\\n- {}'.format(i, ' '.join(topic_words)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(doc_topic): <class 'numpy.ndarray'>\n",
      "shape: (17796, 17)\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#文档-主题（Document-Topic）分布\n",
    "doc_topic = model.doc_topic_  \n",
    "print(\"type(doc_topic): {}\".format(type(doc_topic)))  \n",
    "print(\"shape: {}\".format(doc_topic.shape))\n",
    "topicList=[]\n",
    "#输出所有文档主题到excel\n",
    "for n in range(len(doc_topic)):  \n",
    "    topic_most_pr = doc_topic[n].argmax()\n",
    "    topicList.append(topic_most_pr)\n",
    "    #print(\"doc: {} topic: {}\".format(n, topic_most_pr))  \n",
    "topicdf=pd.DataFrame(topicList)\n",
    "df['topic']=topicList\n",
    "df.to_excel('metoo17topics*20words.xlsx',sheet_name='Sheet1')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
